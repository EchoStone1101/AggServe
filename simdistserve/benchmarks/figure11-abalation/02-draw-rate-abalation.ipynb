{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target = '(400.0, 100.0)'\n",
    "is_notebook_mode = 'get_ipython' in globals()\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def parse_args(args_=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--target\", type=str, default=target)\n",
    "    args = parser.parse_args(args_)\n",
    "    return args\n",
    "\n",
    "\n",
    "if not is_notebook_mode:\n",
    "    args = parse_args()\n",
    "    target = args.target\n",
    "target = eval(target)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcb5d4e767e36976",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"figure\").mkdir(exist_ok=True)\n",
    "Path(\"visual\").mkdir(exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89e460095ffd1517",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "import pandas as pd\n",
    "\n",
    "assert Namespace\n",
    "\n",
    "# Get all files with format '*.latency.csv' from root_dir\n",
    "# root_dir = Path(\"fig11-abalation-log\")\n",
    "root_dir = Path(\"result\")\n",
    "latency_file_paths = sorted(list(root_dir.glob(\"*.latency.csv\")))\n",
    "experiment_log_paths = sorted(list(root_dir.glob(\"*.log\")))\n",
    "columns = ['backend', 'rate', 'target', 'attainment', 'latency']"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dfs = []\n",
    "namespaces = []\n",
    "for latency_file_path, experiment_log_path in zip(latency_file_paths, experiment_log_paths):\n",
    "    # read experiment_log_path and log the namespace\n",
    "    # with open(experiment_log_path, 'r') as f:\n",
    "    #     exp_args = f.read()\n",
    "    #     exp_args = eval(exp_args)\n",
    "    #     namespaces.append(exp_args)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(latency_file_path)\n",
    "        dfs.append(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf162cc0a9334b35",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "big_df = pd.concat(dfs, ignore_index=True)\n",
    "big_df['ngpu'] = big_df['tp_prefill'] * big_df['pp_prefill'] + big_df['tp_decode'] * big_df['pp_decode']\n",
    "big_df['per_gpu_rate'] = big_df['rate'] / big_df['ngpu']\n",
    "big_df['goodput@90'] = big_df.apply(\n",
    "    lambda x: x['rate'] / x['ngpu'] if x['attainment'] >= 90 else 0,\n",
    "    axis=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69a03ddf577d3c5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "big_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3348ed969bcfabf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_machine = 4\n",
    "max_gpu_per_node = 8\n",
    "\n",
    "\n",
    "def can_fit_low_affinity_distserve(x):\n",
    "    a, b, c, d = x['tp_prefill'], x['pp_prefill'], x['tp_decode'], x['pp_decode']\n",
    "    for pp_common in range(1, max_machine + 1):\n",
    "        bp = b / pp_common\n",
    "        dp = d / pp_common\n",
    "        # If either bp or dp is not int, skip\n",
    "        if int(bp) != bp or int(dp) != dp:\n",
    "            continue\n",
    "        # Check if the segment can be placed inside a node\n",
    "        if a * bp + c * dp <= max_gpu_per_node:\n",
    "            return True\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def can_fit_low_affinity(x):\n",
    "    if x['backend'] == 'distserve':\n",
    "        return can_fit_low_affinity_distserve(x)\n",
    "    else:\n",
    "        return True\n",
    "    pass\n",
    "\n",
    "\n",
    "big_df['low_affin'] = big_df.apply(can_fit_low_affinity, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27819a9a9d826d68",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "big_df.sort_values(by=['backend', 'per_gpu_rate', 'tp_prefill', 'pp_prefill', 'tp_decode', 'pp_decode'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60850f3b183a849",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "big_df['target_evaled'] = big_df['target'].apply(eval)\n",
    "figure_11_left_df = big_df[\n",
    "    (big_df['pd'] == 'both')\n",
    "    & (big_df['target_evaled'] == target)\n",
    "    ].copy()\n",
    "\n",
    "figure_11_left_df = figure_11_left_df.sort_values(by=[\n",
    "    'backend', 'tp_prefill', 'pp_prefill', 'tp_decode', 'pp_decode',\n",
    "    'rate'\n",
    "])\n",
    "# Choose the config with the best goodput in each group\n",
    "figure_11_distserve_high = figure_11_left_df[\n",
    "    (figure_11_left_df['backend'] == 'distserve')\n",
    "]\n",
    "figure_11_distserve_low = figure_11_left_df[\n",
    "    (figure_11_left_df['backend'] == 'distserve')\n",
    "    & (figure_11_left_df['low_affin'])\n",
    "    ]\n",
    "figure_11_vllm_high = figure_11_left_df[\n",
    "    (figure_11_left_df['backend'] == 'vllm')\n",
    "]\n",
    "figure_11_vllm_low = figure_11_left_df[\n",
    "    (figure_11_left_df['backend'] == 'vllm')\n",
    "    & (figure_11_left_df['pp_prefill'] == 1)\n",
    "    & (figure_11_left_df['tp_prefill'] == 1)\n",
    "    ]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbddcd857c4232f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure_11_distserve_high"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eefd058d2a113f3b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure_11_distserve_low"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "919167a14ff23dc2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure_11_vllm_high"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afb7980c8f37f3ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure_11_vllm_low"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f75057473fc9c5ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a769e97e148bf255",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the `figure_11_distserve_high`for some configurations\n",
    "# tp_prefill = 1, pp_prefill = 1, tp_decode = 1, pp_decode = 1\n",
    "# x-axis: rate\n",
    "# y-axis: attainment\n",
    "# find all combination of tp_prefill, pp_prefill, tp_decode, pp_decode\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "configs = figure_11_distserve_high[['tp_prefill', 'pp_prefill', 'tp_decode', 'pp_decode']].drop_duplicates()\n",
    "df = figure_11_distserve_high\n",
    "\n",
    "for tp_prefill, pp_prefill, tp_decode, pp_decode in configs.values:\n",
    "    config_df = df[\n",
    "        (df['tp_prefill'] == tp_prefill) & (df['pp_prefill'] == pp_prefill) &\n",
    "        (df['tp_decode'] == tp_decode) & (df['pp_decode'] == pp_decode)\n",
    "        ]\n",
    "    # plot this inside a plotly plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=config_df['per_gpu_rate'], y=config_df['attainment'],\n",
    "        mode='lines+markers', name=f\"p{tp_prefill}{pp_prefill}{tp_decode}{pp_decode}-distserve\"\n",
    "    ))\n",
    "\n",
    "# fig add title\n",
    "fig.update_layout(\n",
    "    title=\"DistServe\",\n",
    "    xaxis_title=\"Per-GPU Rate (tokens/s)\",\n",
    "    yaxis_title=\"Attainment (%)\",\n",
    "    legend_title=\"Configuration\"\n",
    ")\n",
    "\n",
    "# Export to html\n",
    "fig.write_html(\"visual/figure_11_distserve_high.html\")\n",
    "if is_notebook_mode:\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5f32d90f99e3ad4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the `figure_11_vllm_high`for some configurations\n",
    "# tp_prefill = 1, pp_prefill = 1\n",
    "# x-axis: rate\n",
    "# y-axis: attainment\n",
    "# find all combination of tp_prefill, pp_prefill\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "configs = figure_11_vllm_high[['tp_prefill', 'pp_prefill']].drop_duplicates()\n",
    "df = figure_11_vllm_high\n",
    "\n",
    "for tp_prefill, pp_prefill in configs.values:\n",
    "    config_df = df[\n",
    "        (df['tp_prefill'] == tp_prefill) & (df['pp_prefill'] == pp_prefill)\n",
    "        ]\n",
    "    # plot this inside a plotly plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=config_df['per_gpu_rate'], y=config_df['attainment'],\n",
    "        mode='lines+markers', name=f\"p{tp_prefill}{pp_prefill}-vllm\"\n",
    "    ))\n",
    "\n",
    "# fig add title\n",
    "fig.update_layout(\n",
    "    title=\"vLLM++\",\n",
    "    xaxis_title=\"Per-GPU Rate (tokens/s)\",\n",
    "    yaxis_title=\"Attainment (%)\",\n",
    "    legend_title=\"Configuration\"\n",
    ")\n",
    "# Export to html\n",
    "fig.write_html(\"visual/figure_11_vllm_high.html\")\n",
    "if is_notebook_mode:\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "850a4845f690b806",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the `figure_11_distserve_high`for some configurations\n",
    "# tp_prefill = 1, pp_prefill = 1, tp_decode = 1, pp_decode = 1\n",
    "# x-axis: rate\n",
    "# y-axis: attainment\n",
    "# find all combination of tp_prefill, pp_prefill, tp_decode, pp_decode\n",
    "\n",
    "configs = figure_11_distserve_high[['tp_prefill', 'pp_prefill', 'tp_decode', 'pp_decode']].drop_duplicates()\n",
    "df = figure_11_distserve_high\n",
    "\n",
    "for tp_prefill, pp_prefill, tp_decode, pp_decode in configs.values:\n",
    "    config_df = df[\n",
    "        (df['tp_prefill'] == tp_prefill) & (df['pp_prefill'] == pp_prefill) &\n",
    "        (df['tp_decode'] == tp_decode) & (df['pp_decode'] == pp_decode)\n",
    "        ]\n",
    "    # plot this inside a plotly plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=config_df['per_gpu_rate'], y=config_df['attainment'],\n",
    "        mode='lines+markers', name=f\"p{tp_prefill}{pp_prefill}{tp_decode}{pp_decode}-distserve\"\n",
    "    ))\n",
    "\n",
    "# Plot the `figure_11_vllm_high`for some configurations\n",
    "# tp_prefill = 1, pp_prefill = 1\n",
    "# x-axis: rate\n",
    "# y-axis: attainment\n",
    "# find all combination of tp_prefill, pp_prefill\n",
    "\n",
    "configs = figure_11_vllm_high[['tp_prefill', 'pp_prefill']].drop_duplicates()\n",
    "df = figure_11_vllm_high\n",
    "\n",
    "for tp_prefill, pp_prefill in configs.values:\n",
    "    config_df = df[\n",
    "        (df['tp_prefill'] == tp_prefill) & (df['pp_prefill'] == pp_prefill)\n",
    "        ]\n",
    "    # plot this inside a plotly plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=config_df['per_gpu_rate'], y=config_df['attainment'],\n",
    "        mode='lines+markers', name=f\"p{tp_prefill}{pp_prefill}-vllm\"\n",
    "    ))\n",
    "\n",
    "# fig add title\n",
    "fig.update_layout(\n",
    "    title=\"Figure 11: Abalation Study (DistServe and vLLM)\",\n",
    "    xaxis_title=\"Per-GPU Rate (tokens/s)\",\n",
    "    yaxis_title=\"Attainment (%)\",\n",
    "    legend_title=\"Configuration\"\n",
    ")\n",
    "fig.write_html(\"visual/figure_11.full.html\")\n",
    "if is_notebook_mode:\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97da25d4cb5d76ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find the best config that has the highest goodput@90 and attainment\n",
    "def get_top_config(df):\n",
    "    max_per_gpu_rate = max(df['per_gpu_rate'].unique())\n",
    "    df2 = df[df['per_gpu_rate'] == max_per_gpu_rate]\n",
    "    df3 = df2.sort_values(by=['goodput@90', 'attainment'], ascending=False, )\n",
    "    r = df3.iloc[0][[\n",
    "        \"tp_prefill\",\n",
    "        \"pp_prefill\",\n",
    "        \"tp_decode\",\n",
    "        \"pp_decode\",\n",
    "    ]]\n",
    "    return r\n",
    "\n",
    "\n",
    "def add_plotly_trace(fig, df: 'DataFrame', trace: str):\n",
    "    tp_prefill, pp_prefill, tp_decode, pp_decode = get_top_config(df)\n",
    "    config_df = df[\n",
    "        (df['tp_prefill'] == tp_prefill) & (df['pp_prefill'] == pp_prefill) &\n",
    "        (df['tp_decode'] == tp_decode) & (df['pp_decode'] == pp_decode)\n",
    "        ]\n",
    "    if 'vllm' in trace:\n",
    "        name = f\"{trace}-p{tp_prefill}{pp_prefill}\"\n",
    "        pass\n",
    "    else:\n",
    "        name = f\"{trace}-p{tp_prefill}{pp_prefill}{tp_decode}{pp_decode}\"\n",
    "        pass\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=config_df['per_gpu_rate'], y=config_df['attainment'],\n",
    "        mode='lines+markers', name=name\n",
    "    ))\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48c46744186936b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "add_plotly_trace(fig, figure_11_distserve_high, \"disthigh\")\n",
    "add_plotly_trace(fig, figure_11_distserve_low, \"distlow\")\n",
    "add_plotly_trace(fig, figure_11_vllm_high, \"vllm++\")\n",
    "add_plotly_trace(fig, figure_11_vllm_low, \"vllm\")\n",
    "fig.update_layout(\n",
    "    title=\"Figure 11: Abalation Study (DistServe and vLLM)<br>\"\n",
    "          \"<sup>The figure shows that DistHigh > DistLow > vLLM++ > vLLM (vLLM++ and vLLM overlaps) </sup>\",\n",
    "    xaxis_title=\"Per-GPU Rate (tokens/s)\",\n",
    "    yaxis_title=\"Attainment (%)\",\n",
    "    legend_title=\"Configuration\"\n",
    ")\n",
    "fig.write_html(\"visual/figure_11.html\")\n",
    "if is_notebook_mode:\n",
    "    fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8c4a3d5380bbf97",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def add_matplotlib_trace(fig, df: 'DataFrame', trace: str):\n",
    "    tp_prefill, pp_prefill, tp_decode, pp_decode = get_top_config(df)\n",
    "    config_df = df[\n",
    "        (df['tp_prefill'] == tp_prefill) & (df['pp_prefill'] == pp_prefill) &\n",
    "        (df['tp_decode'] == tp_decode) & (df['pp_decode'] == pp_decode)\n",
    "        ]\n",
    "    if 'vllm' in trace:\n",
    "        name = f\"{trace}-p{tp_prefill}{pp_prefill}\"\n",
    "        pass\n",
    "    else:\n",
    "        name = f\"{trace}-p{tp_prefill}{pp_prefill}{tp_decode}{pp_decode}\"\n",
    "        pass\n",
    "\n",
    "    fig.plot(\n",
    "        config_df['per_gpu_rate'], config_df['attainment'],\n",
    "        label=name,\n",
    "        marker='o',\n",
    "    )\n",
    "    return config_df['attainment'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5ff643a25130b2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a line chart with 4 curves\n",
    "# x-axis: per_gpu_rate\n",
    "# y-axis: attainment\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "a = add_matplotlib_trace(ax, figure_11_distserve_high, \"disthigh\")\n",
    "b = add_matplotlib_trace(ax, figure_11_distserve_low, \"distlow\")\n",
    "c = add_matplotlib_trace(ax, figure_11_vllm_high, \"vllm++\")\n",
    "d = add_matplotlib_trace(ax, figure_11_vllm_low, \"vllm\")\n",
    "\n",
    "plt.title(\"Figure 11: Abalation Study (DistServe and vLLM)\")\n",
    "plt.xlabel(\"Per-GPU Rate (req/s)\")\n",
    "plt.ylabel(\"SLO Attainment (%)\")\n",
    "plt.legend()\n",
    "fig.savefig(\"figure/figure_11a.png\")\n",
    "if is_notebook_mode:\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c147288371ee90f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_points = {\n",
    "    \"dist++\": a,\n",
    "    \"dist\": b,\n",
    "    \"vllm++\": c,\n",
    "    \"vllm\": d,\n",
    "}\n",
    "with open(\"figure/figure_11a.json\", \"w\") as f:\n",
    "    import json\n",
    "\n",
    "    json.dump(data_points, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8998c00690fc1021",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
